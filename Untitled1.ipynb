{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fad0826-40ac-4fb5-8ca7-e67e0b4c0019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ChannelSELayer3D(nn.Module):\n",
    "    \"\"\"\n",
    "    3D extension of Squeeze-and-Excitation (SE) block described in:\n",
    "        *Hu et al., Squeeze-and-Excitation Networks, arXiv:1709.01507*\n",
    "        *Zhu et al., AnatomyNet, arXiv:arXiv:1808.05238*\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_channels, reduction_ratio=2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_channels (int): No of input channels\n",
    "            reduction_ratio (int): By how much should the num_channels should be reduced\n",
    "        \"\"\"\n",
    "        super(ChannelSELayer3D, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        num_channels_reduced = num_channels // reduction_ratio\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        self.fc1 = nn.Linear(num_channels, num_channels_reduced, bias=True)\n",
    "        self.fc2 = nn.Linear(num_channels_reduced, num_channels, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_channels, D, H, W = x.size()\n",
    "        # Average along each channel\n",
    "        squeeze_tensor = self.avg_pool(x)\n",
    "\n",
    "        # channel excitation\n",
    "        fc_out_1 = self.relu(self.fc1(squeeze_tensor.view(batch_size, num_channels)))\n",
    "        fc_out_2 = self.sigmoid(self.fc2(fc_out_1))\n",
    "\n",
    "        output_tensor = torch.mul(x, fc_out_2.view(batch_size, num_channels, 1, 1, 1))\n",
    "\n",
    "        return output_tensor\n",
    "\n",
    "\n",
    "class SpatialSELayer3D(nn.Module):\n",
    "    \"\"\"\n",
    "    3D extension of SE block -- squeezing spatially and exciting channel-wise described in:\n",
    "        *Roy et al., Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks, MICCAI 2018*\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_channels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_channels (int): No of input channels\n",
    "        \"\"\"\n",
    "        super(SpatialSELayer3D, self).__init__()\n",
    "        self.conv = nn.Conv3d(num_channels, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, weights=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            weights (torch.Tensor): weights for few shot learning\n",
    "            x: X, shape = (batch_size, num_channels, D, H, W)\n",
    "        Returns:\n",
    "            (torch.Tensor): output_tensor\n",
    "        \"\"\"\n",
    "        # channel squeeze\n",
    "        batch_size, channel, D, H, W = x.size()\n",
    "\n",
    "        if weights:\n",
    "            weights = weights.view(1, channel, 1, 1)\n",
    "            out = F.conv2d(x, weights)\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "\n",
    "        squeeze_tensor = self.sigmoid(out)\n",
    "\n",
    "        # spatial excitation\n",
    "        output_tensor = torch.mul(x, squeeze_tensor.view(batch_size, 1, D, H, W))\n",
    "\n",
    "        return output_tensor\n",
    "\n",
    "\n",
    "class ChannelSpatialSELayer3D(nn.Module):\n",
    "    \"\"\"\n",
    "       3D extension of concurrent spatial and channel squeeze & excitation:\n",
    "           *Roy et al., Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks, arXiv:1803.02579*\n",
    "       \"\"\"\n",
    "\n",
    "    def __init__(self, num_channels, reduction_ratio=2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_channels (int): No of input channels\n",
    "            reduction_ratio (int): By how much should the num_channels should be reduced\n",
    "        \"\"\"\n",
    "        super(ChannelSpatialSELayer3D, self).__init__()\n",
    "        self.cSE = ChannelSELayer3D(num_channels, reduction_ratio)\n",
    "        self.sSE = SpatialSELayer3D(num_channels)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        output_tensor = torch.max(self.cSE(input_tensor), self.sSE(input_tensor))\n",
    "        return output_tensor\n",
    "\n",
    "\n",
    "def number_of_features_per_level(init_channel_number, num_levels):\n",
    "    return [init_channel_number * 2 ** k for k in range(num_levels)]\n",
    "    \n",
    "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding, is3d):\n",
    "    \"\"\"\n",
    "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
    "    and optional batchnorm/groupnorm.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size(int or tuple): size of the convolving kernel\n",
    "        order (string): order of things, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'gcr' -> groupnorm + conv + ReLU\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "            'bcr' -> batchnorm + conv + ReLU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "        is3d (bool): is3d (bool): if True use Conv3d, otherwise use Conv2d\n",
    "    Return:\n",
    "        list of tuple (name, module)\n",
    "    \"\"\"\n",
    "    assert 'c' in order, \"Conv layer MUST be present\"\n",
    "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
    "\n",
    "    modules = []\n",
    "    for i, char in enumerate(order):\n",
    "        if char == 'r':\n",
    "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
    "        elif char == 'l':\n",
    "            modules.append(('LeakyReLU', nn.LeakyReLU(inplace=True)))\n",
    "        elif char == 'e':\n",
    "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
    "        elif char == 'c':\n",
    "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
    "            bias = not ('g' in order or 'b' in order)\n",
    "            if is3d:\n",
    "                conv = nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias)\n",
    "            else:\n",
    "                conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=bias)\n",
    "\n",
    "            modules.append(('conv', conv))\n",
    "        elif char == 'g':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                num_channels = in_channels\n",
    "            else:\n",
    "                num_channels = out_channels\n",
    "\n",
    "            # use only one group if the given number of groups is greater than the number of channels\n",
    "            if num_channels < num_groups:\n",
    "                num_groups = 1\n",
    "\n",
    "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
    "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
    "        elif char == 'b':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is3d:\n",
    "                bn = nn.BatchNorm3d\n",
    "            else:\n",
    "                bn = nn.BatchNorm2d\n",
    "\n",
    "            if is_before_conv:\n",
    "                modules.append(('batchnorm', bn(in_channels)))\n",
    "            else:\n",
    "                modules.append(('batchnorm', bn(out_channels)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
    "\n",
    "    return modules\n",
    "\n",
    "\n",
    "class SingleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
    "    of operations can be specified via the `order` parameter\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding\n",
    "        is3d (bool): if True use Conv3d, otherwise use Conv2d\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1, is3d=True):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding, is3d):\n",
    "            self.add_module(name, module)\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
    "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
    "    This can be changed however by providing the 'order' argument, e.g. in order\n",
    "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
    "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
    "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "        is3d (bool): if True use Conv3d instead of Conv2d layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1,\n",
    "                 is3d=True):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if encoder:\n",
    "            # we're in the encoder path\n",
    "            conv1_in_channels = in_channels\n",
    "            conv1_out_channels = out_channels // 2\n",
    "            if conv1_out_channels < in_channels:\n",
    "                conv1_out_channels = in_channels\n",
    "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
    "        else:\n",
    "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
    "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
    "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
    "\n",
    "        # conv1\n",
    "        self.add_module('SingleConv1',\n",
    "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding, is3d=is3d))\n",
    "        # conv2\n",
    "        self.add_module('SingleConv2',\n",
    "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding, is3d=is3d))\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block that can be used instead of standard DoubleConv in the Encoder module.\n",
    "    Motivated by: https://arxiv.org/pdf/1706.00120.pdf\n",
    "\n",
    "    Notice we use ELU instead of ReLU (order='cge') and put non-linearity after the groupnorm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='cge', num_groups=8, is3d=True, **kwargs):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            # conv1x1 for increasing the number of channels\n",
    "            if is3d:\n",
    "                self.conv1 = nn.Conv3d(in_channels, out_channels, 1)\n",
    "            else:\n",
    "                self.conv1 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        else:\n",
    "            self.conv1 = nn.Identity()\n",
    "\n",
    "        # residual block\n",
    "        self.conv2 = SingleConv(out_channels, out_channels, kernel_size=kernel_size, order=order, num_groups=num_groups,\n",
    "                                is3d=is3d)\n",
    "        # remove non-linearity from the 3rd convolution since it's going to be applied after adding the residual\n",
    "        n_order = order\n",
    "        for c in 'rel':\n",
    "            n_order = n_order.replace(c, '')\n",
    "        self.conv3 = SingleConv(out_channels, out_channels, kernel_size=kernel_size, order=n_order,\n",
    "                                num_groups=num_groups, is3d=is3d)\n",
    "\n",
    "        # create non-linearity separately\n",
    "        if 'l' in order:\n",
    "            self.non_linearity = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        elif 'e' in order:\n",
    "            self.non_linearity = nn.ELU(inplace=True)\n",
    "        else:\n",
    "            self.non_linearity = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply first convolution to bring the number of channels to out_channels\n",
    "        residual = self.conv1(x)\n",
    "\n",
    "        # residual block\n",
    "        out = self.conv2(residual)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.non_linearity(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetBlockSE(ResNetBlock):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='cge', num_groups=8, se_module='scse', **kwargs):\n",
    "        super(ResNetBlockSE, self).__init__(\n",
    "            in_channels, out_channels, kernel_size=kernel_size, order=order,\n",
    "            num_groups=num_groups, **kwargs)\n",
    "        assert se_module in ['scse', 'cse', 'sse']\n",
    "        if se_module == 'scse':\n",
    "            self.se_module = ChannelSpatialSELayer3D(num_channels=out_channels, reduction_ratio=1)\n",
    "        elif se_module == 'cse':\n",
    "            self.se_module = ChannelSELayer3D(num_channels=out_channels, reduction_ratio=1)\n",
    "        elif se_module == 'sse':\n",
    "            self.se_module = SpatialSELayer3D(num_channels=out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = super().forward(x)\n",
    "        out = self.se_module(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module from the encoder path consisting of the optional max\n",
    "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
    "    from the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
    "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
    "    a basic module (DoubleConv or ResNetBlock).\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        pool_type (str): pooling layer: 'max' or 'avg'\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "        is3d (bool): use 3d or 2d convolutions/pooling operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
    "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
    "                 num_groups=8, padding=1, is3d=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        assert pool_type in ['max', 'avg']\n",
    "        if apply_pooling:\n",
    "            if pool_type == 'max':\n",
    "                if is3d:\n",
    "                    self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "                else:\n",
    "                    self.pooling = nn.MaxPool2d(kernel_size=pool_kernel_size)\n",
    "            else:\n",
    "                if is3d:\n",
    "                    self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
    "                else:\n",
    "                    self.pooling = nn.AvgPool2d(kernel_size=pool_kernel_size)\n",
    "        else:\n",
    "            self.pooling = None\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=True,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding,\n",
    "                                         is3d=is3d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pooling is not None:\n",
    "            x = self.pooling(x)\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module for decoder path consisting of the upsampling layer\n",
    "    (either learned ConvTranspose3d or nearest neighbor interpolation)\n",
    "    followed by a basic module (DoubleConv or ResNetBlock).\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
    "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
    "            from the corresponding encoder\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "        upsample (bool): should the input be upsampled\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
    "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1, upsample=True, is3d=True):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        if upsample:\n",
    "            if basic_module == DoubleConv:\n",
    "                # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
    "                self.upsampling = InterpolateUpsampling(mode=mode)\n",
    "                # concat joining\n",
    "                self.joining = partial(self._joining, concat=True)\n",
    "            else:\n",
    "                # if basic_module=ResNetBlock use transposed convolution upsampling and summation joining\n",
    "                self.upsampling = TransposeConvUpsampling(in_channels=in_channels, out_channels=out_channels,\n",
    "                                                          kernel_size=conv_kernel_size, scale_factor=scale_factor)\n",
    "                # sum joining\n",
    "                self.joining = partial(self._joining, concat=False)\n",
    "                # adapt the number of in_channels for the ResNetBlock\n",
    "                in_channels = out_channels\n",
    "        else:\n",
    "            # no upsampling\n",
    "            self.upsampling = NoUpsampling()\n",
    "            # concat joining\n",
    "            self.joining = partial(self._joining, concat=True)\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=False,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding,\n",
    "                                         is3d=is3d)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
    "        x = self.joining(encoder_features, x)\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _joining(encoder_features, x, concat):\n",
    "        if concat:\n",
    "            return torch.cat((encoder_features, x), dim=1)\n",
    "        else:\n",
    "            return encoder_features + x\n",
    "\n",
    "\n",
    "def create_encoders(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n",
    "                    pool_kernel_size, is3d):\n",
    "    # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
    "    encoders = []\n",
    "    for i, out_feature_num in enumerate(f_maps):\n",
    "        if i == 0:\n",
    "            # apply conv_coord only in the first encoder if any\n",
    "            encoder = Encoder(in_channels, out_feature_num,\n",
    "                              apply_pooling=False,  # skip pooling in the firs encoder\n",
    "                              basic_module=basic_module,\n",
    "                              conv_layer_order=layer_order,\n",
    "                              conv_kernel_size=conv_kernel_size,\n",
    "                              num_groups=num_groups,\n",
    "                              padding=conv_padding,\n",
    "                              is3d=is3d)\n",
    "        else:\n",
    "            encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
    "                              basic_module=basic_module,\n",
    "                              conv_layer_order=layer_order,\n",
    "                              conv_kernel_size=conv_kernel_size,\n",
    "                              num_groups=num_groups,\n",
    "                              pool_kernel_size=pool_kernel_size,\n",
    "                              padding=conv_padding,\n",
    "                              is3d=is3d)\n",
    "\n",
    "        encoders.append(encoder)\n",
    "\n",
    "    return nn.ModuleList(encoders)\n",
    "\n",
    "\n",
    "def create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups, is3d):\n",
    "    # create decoder path consisting of the Decoder modules. The length of the decoder list is equal to `len(f_maps) - 1`\n",
    "    decoders = []\n",
    "    reversed_f_maps = list(reversed(f_maps))\n",
    "    for i in range(len(reversed_f_maps) - 1):\n",
    "        if basic_module == DoubleConv:\n",
    "            in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
    "        else:\n",
    "            in_feature_num = reversed_f_maps[i]\n",
    "\n",
    "        out_feature_num = reversed_f_maps[i + 1]\n",
    "\n",
    "        decoder = Decoder(in_feature_num, out_feature_num,\n",
    "                          basic_module=basic_module,\n",
    "                          conv_layer_order=layer_order,\n",
    "                          conv_kernel_size=conv_kernel_size,\n",
    "                          num_groups=num_groups,\n",
    "                          padding=conv_padding,\n",
    "                          is3d=is3d)\n",
    "        decoders.append(decoder)\n",
    "    return nn.ModuleList(decoders)\n",
    "\n",
    "\n",
    "class AbstractUpsampling(nn.Module):\n",
    "    \"\"\"\n",
    "    Abstract class for upsampling. A given implementation should upsample a given 5D input tensor using either\n",
    "    interpolation or learned transposed convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, upsample):\n",
    "        super(AbstractUpsampling, self).__init__()\n",
    "        self.upsample = upsample\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        # get the spatial dimensions of the output given the encoder_features\n",
    "        output_size = encoder_features.size()[2:]\n",
    "        # upsample the input and return\n",
    "        return self.upsample(x, output_size)\n",
    "\n",
    "\n",
    "class InterpolateUpsampling(AbstractUpsampling):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        mode (str): algorithm used for upsampling:\n",
    "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
    "            used only if transposed_conv is False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode='nearest'):\n",
    "        upsample = partial(self._interpolate, mode=mode)\n",
    "        super().__init__(upsample)\n",
    "\n",
    "    @staticmethod\n",
    "    def _interpolate(x, size, mode):\n",
    "        return F.interpolate(x, size=size, mode=mode)\n",
    "\n",
    "\n",
    "class TransposeConvUpsampling(AbstractUpsampling):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        in_channels (int): number of input channels for transposed conv\n",
    "            used only if transposed_conv is True\n",
    "        out_channels (int): number of output channels for transpose conv\n",
    "            used only if transposed_conv is True\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "            used only if transposed_conv is True\n",
    "        scale_factor (int or tuple): stride of the convolution\n",
    "            used only if transposed_conv is True\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=None, out_channels=None, kernel_size=3, scale_factor=(2, 2, 2)):\n",
    "        # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
    "        upsample = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=scale_factor,\n",
    "                                      padding=1)\n",
    "        super().__init__(upsample)\n",
    "\n",
    "\n",
    "class NoUpsampling(AbstractUpsampling):\n",
    "    def __init__(self):\n",
    "        super().__init__(self._no_upsampling)\n",
    "\n",
    "    @staticmethod\n",
    "    def _no_upsampling(x, size):\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AbstractUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for standard and residual UNet.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output segmentation masks;\n",
    "            Note that the of out_channels might correspond to either\n",
    "            different semantic classes or to different binary segmentation mask.\n",
    "            It's up to the user of the class to interpret the out_channels and\n",
    "            use the proper loss criterion during training (i.e. CrossEntropyLoss (multi-class)\n",
    "            or BCEWithLogitsLoss (two-class) respectively)\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the final 1x1 convolution,\n",
    "            otherwise apply nn.Softmax. In effect only if `self.training == False`, i.e. during validation/testing\n",
    "        basic_module: basic model for the encoder/decoder (DoubleConv, ResNetBlock, ....)\n",
    "        layer_order (string): determines the order of layers in `SingleConv` module.\n",
    "            E.g. 'crg' stands for GroupNorm3d+Conv3d+ReLU. See `SingleConv` for more info\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "            default: 4\n",
    "        is_segmentation (bool): if True and the model is in eval mode, Sigmoid/Softmax normalization is applied\n",
    "            after the final convolution; if False (regression problem) the normalization layer is skipped\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "        is3d (bool): if True the model is 3D, otherwise 2D, default: True\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid, basic_module, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_kernel_size=3, pool_kernel_size=2,\n",
    "                 conv_padding=1, classes=1, input_slice=1, is3d=True):\n",
    "        super(AbstractUNet, self).__init__()\n",
    "        self.is3d = is3d\n",
    "        self.input_layer = None\n",
    "        self.output_layer = None\n",
    "        if is3d is not None:\n",
    "            self.input_layer = nn.Conv3d(input_slice, f_maps, 3, padding=1)\n",
    "            self.output_layer =  nn.Conv2d(f_maps, classes, 3, padding=1)\n",
    "        if isinstance(f_maps, int):\n",
    "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
    "\n",
    "        assert isinstance(f_maps, list) or isinstance(f_maps, tuple)\n",
    "        assert len(f_maps) > 1, \"Required at least 2 levels in the U-Net\"\n",
    "        if 'g' in layer_order:\n",
    "            assert num_groups is not None, \"num_groups must be specified if GroupNorm is used\"\n",
    "\n",
    "        # create encoder path\n",
    "\n",
    "        self.encoders = create_encoders(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order,\n",
    "                                        num_groups, pool_kernel_size, is3d)\n",
    "\n",
    "        # create decoder path\n",
    "        self.decoders = create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n",
    "                                        is3d)\n",
    "\n",
    "        # in the last layer a 1×1 convolution reduces the number of output channels to the number of labels\n",
    "        if self.is3d:\n",
    "            self.final_conv = nn.Conv3d(f_maps[0], out_channels, 1)\n",
    "        else:\n",
    "            self.final_conv = nn.Conv2d(f_maps[0], out_channels, 1)\n",
    "\n",
    "        if is_segmentation:\n",
    "            # semantic segmentation problem\n",
    "            if final_sigmoid:\n",
    "                self.final_activation = nn.Sigmoid()\n",
    "            else:\n",
    "                self.final_activation = nn.Softmax(dim=1)\n",
    "        else:\n",
    "            # regression problem\n",
    "            self.final_activation = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.is3d:\n",
    "            x = self.input_layer(x).squeeze(2).unsqueeze(1)\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            encoders_features.insert(0, x)\n",
    "\n",
    "        # remove the last encoder's output from the list\n",
    "        # !!remember: it's the 1st in the list\n",
    "        encoders_features = encoders_features[1:]\n",
    "\n",
    "        # decoder part\n",
    "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
    "            # pass the output from the corresponding encoder and the output\n",
    "            # of the previous decoder\n",
    "            x = decoder(encoder_features, x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        if self.is3d:\n",
    "            x = self.output_layer(x.squeeze(1))\n",
    "\n",
    "        # apply final_activation (i.e. Sigmoid or Softmax) only during prediction.\n",
    "        # During training the network outputs logits\n",
    "        # if not self.training and self.final_activation is not None:\n",
    "        #     x = self.final_activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet3D(AbstractUNet):\n",
    "    \"\"\"\n",
    "    3DUnet model from\n",
    "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
    "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
    "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1, input_slice=1, classes=1, **kwargs):\n",
    "        super(UNet3D, self).__init__(in_channels=in_channels,\n",
    "                                     out_channels=out_channels,\n",
    "                                     final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv,\n",
    "                                     f_maps=f_maps,\n",
    "                                     layer_order=layer_order,\n",
    "                                     num_groups=num_groups,\n",
    "                                     num_levels=num_levels,\n",
    "                                     is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding,\n",
    "                                     input_slice=input_slice,\n",
    "                                     classes=classes,\n",
    "                                     is3d=True,\n",
    "                                    )\n",
    "\n",
    "\n",
    "class ResidualUNet3D(AbstractUNet):\n",
    "    \"\"\"\n",
    "    Residual 3DUnet model implementation based on https://arxiv.org/pdf/1706.00120.pdf.\n",
    "    Uses ResNetBlock as a basic building block, summation joining instead\n",
    "    of concatenation joining and transposed convolutions for upsampling (watch out for block artifacts).\n",
    "    Since the model effectively becomes a residual net, in theory it allows for deeper UNet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=5, is_segmentation=True, conv_padding=1, input_slice=1, classes=1, **kwargs):\n",
    "        super(ResidualUNet3D, self).__init__(in_channels=in_channels,\n",
    "                                             out_channels=out_channels,\n",
    "                                             final_sigmoid=final_sigmoid,\n",
    "                                             basic_module=ResNetBlock,\n",
    "                                             f_maps=f_maps,\n",
    "                                             layer_order=layer_order,\n",
    "                                             num_groups=num_groups,\n",
    "                                             num_levels=num_levels,\n",
    "                                             is_segmentation=is_segmentation,\n",
    "                                             conv_padding=conv_padding,\n",
    "                                             input_slice=input_slice,\n",
    "                                             classes=classes,\n",
    "                                             is3d=True\n",
    "                                            )\n",
    "\n",
    "\n",
    "class ResidualUNetSE3D(AbstractUNet):\n",
    "    \"\"\"_summary_\n",
    "    Residual 3DUnet model implementation with squeeze and excitation based on \n",
    "    https://arxiv.org/pdf/1706.00120.pdf.\n",
    "    Uses ResNetBlockSE as a basic building block, summation joining instead\n",
    "    of concatenation joining and transposed convolutions for upsampling (watch\n",
    "    out for block artifacts). Since the model effectively becomes a residual\n",
    "    net, in theory it allows for deeper UNet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=5, is_segmentation=True, conv_padding=1, input_slice=1, classes=1, **kwargs):\n",
    "        super(ResidualUNetSE3D, self).__init__(in_channels=in_channels,\n",
    "                                               out_channels=out_channels,\n",
    "                                               final_sigmoid=final_sigmoid,\n",
    "                                               basic_module=ResNetBlockSE,\n",
    "                                               f_maps=f_maps,\n",
    "                                               layer_order=layer_order,\n",
    "                                               num_groups=num_groups,\n",
    "                                               num_levels=num_levels,\n",
    "                                               is_segmentation=is_segmentation,\n",
    "                                               conv_padding=conv_padding,\n",
    "                                               input_slice=input_slice,\n",
    "                                               classes=classes,\n",
    "                                               is3d=True)\n",
    "\n",
    "\n",
    "class UNet2D(AbstractUNet):\n",
    "    \"\"\"\n",
    "    2DUnet model from\n",
    "    `\"U-Net: Convolutional Networks for Biomedical Image Segmentation\" <https://arxiv.org/abs/1505.04597>`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=64, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1, input_slice=1, classes=1, **kwargs):\n",
    "        super(UNet2D, self).__init__(in_channels=in_channels,\n",
    "                                     out_channels=out_channels,\n",
    "                                     final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv,\n",
    "                                     f_maps=f_maps,\n",
    "                                     layer_order=layer_order,\n",
    "                                     num_groups=num_groups,\n",
    "                                     num_levels=num_levels,\n",
    "                                     is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding,\n",
    "                                     input_slice=input_slice,\n",
    "                                     classes=classes,\n",
    "                                     is3d=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9f3c14-ea44-4413-881b-7d830b96dfaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ResidualUNet3D(in_channels=1, out_channels=1, final_sigmoid=False, f_maps=64, num_groups=8, num_levels=3, input_slice=65, classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ede2c32-855b-433e-b078-b0b81c5ba37d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ten = torch.randn([2, 65, 1, 112, 112])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2116b54-2a32-47d0-8361-e77df2e4f40e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mC:\\anaconda\\envs\\py39\\lib\\site-packages\\torchsummary\\torchsummary.py:140\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 140\u001b[0m         _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)(\u001b[38;5;241m*\u001b[39mx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\anaconda\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 646\u001b[0m, in \u001b[0;36mAbstractUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis3d:\n\u001b[1;32m--> 646\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# encoder part\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1071\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m-> 1071\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32mC:\\anaconda\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:587\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:582\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[0;32m    572\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    573\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    581\u001b[0m     )\n\u001b[1;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 65, 3, 3, 3], expected input[65, 1, 2, 112, 128] to have 65 channels, but got 1 channels instead",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m65\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m112\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda\\envs\\py39\\lib\\site-packages\\torchsummary\\torchsummary.py:143\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    142\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchsummary. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(executed_layers)\n\u001b[0;32m    146\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "summary(model, (65, 1, 112, 128), batch_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa9f1e1c-f6f7-494d-a247-af7e67df711e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i1 = layer_(input_ten).squeeze(2).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f3517d-5759-47ba-80d7-9df2d94bb365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ccf3936-e0b7-449d-8550-06bd9a475e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = model(input_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc2c450-3d61-4ac9-86ef-db40fcf84764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 112, 112])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df9f157-dc65-474e-a501-1f601d34f35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# layer = nn.Conv2d(64, 1, 3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4081e32-6e2a-4e2d-b38b-e93aab16fc6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = layer(output.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b58bbb1-1a8a-4005-b80c-f578d3c3ae71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 112, 112])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42e291cf-32e7-4f74-b654-f30d0d2dad67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Expected number of channels in input to be divisible by num_groups. num_channels=32, num_groups=5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net2 \u001b[38;5;241m=\u001b[39m \u001b[43mUNet2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_sigmoid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_maps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m65\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 744\u001b[0m, in \u001b[0;36mUNet2D.__init__\u001b[1;34m(self, in_channels, out_channels, final_sigmoid, f_maps, layer_order, num_groups, num_levels, is_segmentation, conv_padding, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, out_channels, final_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, f_maps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, layer_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgcr\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    743\u001b[0m              num_groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, num_levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, is_segmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, conv_padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mUNet2D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfinal_sigmoid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_sigmoid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbasic_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDoubleConv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mf_maps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_maps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mlayer_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnum_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mis_segmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_segmentation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mconv_padding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mis3d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 614\u001b[0m, in \u001b[0;36mAbstractUNet.__init__\u001b[1;34m(self, in_channels, out_channels, final_sigmoid, basic_module, f_maps, layer_order, num_groups, num_levels, is_segmentation, conv_kernel_size, pool_kernel_size, conv_padding, is3d)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m num_groups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_groups must be specified if GroupNorm is used\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;66;03m# create encoder path\u001b[39;00m\n\u001b[1;32m--> 614\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoders \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_encoders\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_maps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasic_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_kernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_kernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis3d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# create decoder path\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoders \u001b[38;5;241m=\u001b[39m create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n\u001b[0;32m    619\u001b[0m                                 is3d)\n",
      "Cell \u001b[1;32mIn[1], line 459\u001b[0m, in \u001b[0;36mcreate_encoders\u001b[1;34m(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups, pool_kernel_size, is3d)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, out_feature_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f_maps):\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;66;03m# apply conv_coord only in the first encoder if any\u001b[39;00m\n\u001b[1;32m--> 459\u001b[0m         encoder \u001b[38;5;241m=\u001b[39m \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_feature_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mapply_pooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# skip pooling in the firs encoder\u001b[39;49;00m\n\u001b[0;32m    461\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mbasic_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasic_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mconv_layer_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mconv_kernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_kernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mis3d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis3d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m         encoder \u001b[38;5;241m=\u001b[39m Encoder(f_maps[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], out_feature_num,\n\u001b[0;32m    469\u001b[0m                           basic_module\u001b[38;5;241m=\u001b[39mbasic_module,\n\u001b[0;32m    470\u001b[0m                           conv_layer_order\u001b[38;5;241m=\u001b[39mlayer_order,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    474\u001b[0m                           padding\u001b[38;5;241m=\u001b[39mconv_padding,\n\u001b[0;32m    475\u001b[0m                           is3d\u001b[38;5;241m=\u001b[39mis3d)\n",
      "Cell \u001b[1;32mIn[1], line 370\u001b[0m, in \u001b[0;36mEncoder.__init__\u001b[1;34m(self, in_channels, out_channels, conv_kernel_size, apply_pooling, pool_kernel_size, pool_type, basic_module, conv_layer_order, num_groups, padding, is3d)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_module \u001b[38;5;241m=\u001b[39m \u001b[43mbasic_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_kernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_layer_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mis3d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis3d\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 253\u001b[0m, in \u001b[0;36mDoubleConv.__init__\u001b[1;34m(self, in_channels, out_channels, encoder, kernel_size, order, num_groups, padding, is3d)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSingleConv1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    249\u001b[0m                 SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n\u001b[0;32m    250\u001b[0m                            padding\u001b[38;5;241m=\u001b[39mpadding, is3d\u001b[38;5;241m=\u001b[39mis3d))\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# conv2\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSingleConv2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m--> 253\u001b[0m                 \u001b[43mSingleConv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv2_in_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv2_out_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis3d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis3d\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[1], line 204\u001b[0m, in \u001b[0;36mSingleConv.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, order, num_groups, padding, is3d)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, out_channels, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgcr\u001b[39m\u001b[38;5;124m'\u001b[39m, num_groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, is3d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28msuper\u001b[39m(SingleConv, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcreate_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis3d\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_module(name, module)\n",
      "Cell \u001b[1;32mIn[1], line 163\u001b[0m, in \u001b[0;36mcreate_conv\u001b[1;34m(in_channels, out_channels, kernel_size, order, num_groups, padding, is3d)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_channels \u001b[38;5;241m<\u001b[39m num_groups:\n\u001b[0;32m    161\u001b[0m         num_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m num_channels \u001b[38;5;241m%\u001b[39m num_groups \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected number of channels in input to be divisible by num_groups. num_channels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_channels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_groups=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_groups\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    164\u001b[0m     modules\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroupnorm\u001b[39m\u001b[38;5;124m'\u001b[39m, nn\u001b[38;5;241m.\u001b[39mGroupNorm(num_groups\u001b[38;5;241m=\u001b[39mnum_groups, num_channels\u001b[38;5;241m=\u001b[39mnum_channels)))\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m char \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: Expected number of channels in input to be divisible by num_groups. num_channels=32, num_groups=5"
     ]
    }
   ],
   "source": [
    "net2 = UNet2D(in_channels=1, out_channels=1, final_sigmoid=False, f_maps=65, num_groups=5, num_levels=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
